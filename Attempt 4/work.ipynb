{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elets.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Iasi.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Kaliningrad.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Kneipeda.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Kolpino_1.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Kolpino_2.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Salsk.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Taldom.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Tyumen.png\n",
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "img_dir = \"data/images\"\n",
    "canny_dir = \"data/canny\"\n",
    "os.makedirs(canny_dir, exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(img_dir):\n",
    "    # print(fname)\n",
    "    img = cv2.imread(os.path.join(img_dir, fname))\n",
    "    # print(img)\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    cv2.imwrite(os.path.join(canny_dir, fname), edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "C:\\Users\\nadyl\\AppData\\Local\\Programs\\Python\\Python310\\python.exe: can't open file 'c:\\\\Users\\\\nadyl\\\\Documents\\\\GitHub\\\\generation-of-building-diagrams\\\\Attempt 4\\\\train_controlnet_lora.py': [Errno 2] No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nadyl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\nadyl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\Scripts\\accelerate.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\accelerate\\commands\\accelerate_cli.py\", line 48, in main\n",
      "    args.func(args)\n",
      "  File \"c:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\accelerate\\commands\\launch.py\", line 1199, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"c:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\accelerate\\commands\\launch.py\", line 778, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['c:\\\\Users\\\\nadyl\\\\Documents\\\\GitHub\\\\generation-of-building-diagrams\\\\.venv\\\\Scripts\\\\python.exe', 'train_controlnet_lora.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--controlnet_model_name_or_path=lllyasviel/sd-controlnet-canny', '--train_data_dir=data', '--output_dir=output', '--caption_file=captions.json', '--resolution=512', '--train_batch_size=1', '--learning_rate=1e-5', '--use_8bit_adam', '--gradient_accumulation_steps=1', '--lr_scheduler=constant', '--num_train_epochs=100', '--validation_prompt=2 здание администрации, 6 вертикальных танкера объемом 10000 м³, 1 вертикальных танкера объемом 500 м³, 4 вертикальных танкеров объемом 50 м³, 2 железнодорожный путь', '--tracker_project_name=building-schemes']' returned non-zero exit status 2.\n"
     ]
    }
   ],
   "source": [
    "accelerate launch train_controlnet_lora.py \\\n",
    "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
    "  --controlnet_model_name_or_path=\"lllyasviel/sd-controlnet-canny\" \\\n",
    "  --train_data_dir=\"data\" \\\n",
    "  --output_dir=\"output\" \\\n",
    "  --caption_file=\"captions.json\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=5 \\\n",
    "  --learning_rate=1e-5 \\\n",
    "  --use_8bit_adam \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --num_train_epochs=100 \\\n",
    "  --validation_prompt=\"2 адм, 6 РВС 10к м, 1 РВС 500 м, 4 РВС 50 м, 2 жд\" \\\n",
    "  --tracker_project_name=\"building-schemes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26b61a",
   "metadata": {},
   "source": [
    "Проверяем все описание на адекватное количество токенов, чтобы не потерять никакой информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85d5da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токенов: 46\n",
      "Текст подходит по длине.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPTokenizer\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "text = \"4 адм, 6 РВС 2к м, 8 ГВС 75 м, 8 ГВС 50 м, 2 жд\"\n",
    "\n",
    "tokens = tokenizer(text, truncation=False, padding=False)\n",
    "num_tokens = len(tokens['input_ids'])\n",
    "\n",
    "print(f\"Количество токенов: {num_tokens}\")\n",
    "\n",
    "if num_tokens > 77:\n",
    "    print(\"Текст слишком длинный и будет обрезан.\")\n",
    "else:\n",
    "    print(\"Текст подходит по длине.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614db645",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weight_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mКомната 5x5, дверь слева, окно справа\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m controlnet \u001b[38;5;241m=\u001b[39m \u001b[43mControlNetModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput/adapter_config.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m pipe \u001b[38;5;241m=\u001b[39m StableDiffusionControlNetPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunwayml/stable-diffusion-v1-5\u001b[39m\u001b[38;5;124m\"\u001b[39m, controlnet\u001b[38;5;241m=\u001b[39mcontrolnet, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m pipe\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;241m=\u001b[39m UniPCMultistepScheduler\u001b[38;5;241m.\u001b[39mfrom_config(pipe\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\diffusers\\models\\modeling_utils.py:811\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m--> 811\u001b[0m         sharded_ckpt_cached_folder, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;66;03m# TODO: https://github.com/huggingface/diffusers/issues/10013\u001b[39;00m\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\diffusers\\utils\\hub_utils.py:439\u001b[0m, in \u001b[0;36m_get_checkpoint_shard_files\u001b[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, proxies, local_files_only, token, user_agent, revision, subfolder)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(index_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    437\u001b[0m     index \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 439\u001b[0m original_shard_filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    440\u001b[0m sharded_metadata \u001b[38;5;241m=\u001b[39m index[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    441\u001b[0m sharded_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_checkpoint_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(index[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyError\u001b[0m: 'weight_map'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from diffusers import UniPCMultistepScheduler\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "prompt = \"Комната 5x5, дверь слева, окно справа\"\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"output/adapter_config.json\", torch_dtype=torch.float16)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Заготовка канни-карты (можно пустую)\n",
    "canny_img = cv2.Canny(cv2.imread(\"data/images/plan1.png\"), 100, 200)\n",
    "canny_img = Image.fromarray(canny_img).convert(\"RGB\")\n",
    "\n",
    "image = pipe(prompt, num_inference_steps=25, image=canny_img).images[0]\n",
    "image.save(\"result.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba70b889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026ba16a878b46c599748c75afc40462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2702a4dd45c14156a33ff847e8a2a5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b3895cd05a445382b37c2f394708c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e133743fbc6a4dcd83cfcac5d0754883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nadyl\\.cache\\huggingface\\hub\\models--runwayml--stable-diffusion-v1-5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b55603d9f324b1fa1a4391d85e691e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642917d055ed4c81aa440b2bda7299e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'UNet2DConditionModel' object has no attribute 'load_adapter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m StableDiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunwayml/stable-diffusion-v1-5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Добавление LoRA\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/adapter_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Папка с adapter_config.json и adapter_model.bin\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     adapter_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilding_lora\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Генерация изображения\u001b[39;00m\n\u001b[0;32m     17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2 адм, 6 РВС 10к м\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\diffusers\\models\\modeling_utils.py:173\u001b[0m, in \u001b[0;36mModelMixin.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_dict[name]\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# call PyTorch's https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1930\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'UNet2DConditionModel' object has no attribute 'load_adapter'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Загрузка базовой модели\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Добавление LoRA\n",
    "pipe.unet.load_adapter(\n",
    "    \"output/adapter_config.json\",  # Папка с adapter_config.json и adapter_model.bin\n",
    "    adapter_name=\"building_lora\"\n",
    ")\n",
    "\n",
    "# Генерация изображения\n",
    "prompt = \"2 адм, 6 РВС 10к м\"\n",
    "image = pipe(prompt, num_inference_steps=50).images[0]\n",
    "image.save(\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ae5bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StableDiffusionControlNetPipeline.__init__() missing 7 required positional arguments: 'vae', 'text_encoder', 'tokenizer', 'unet', 'scheduler', 'safety_checker', and 'feature_extractor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionControlNetPipeline\n\u001b[0;32m      3\u001b[0m controlnet \u001b[38;5;241m=\u001b[39m ControlNetModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlllyasviel/sd-controlnet-canny\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mStableDiffusionControlNetPipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrolnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrolnet\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Загрузка LoRA в UNet\u001b[39;00m\n\u001b[0;32m      9\u001b[0m pipe\u001b[38;5;241m.\u001b[39munet\u001b[38;5;241m.\u001b[39mload_attn_procs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/adapter_config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: StableDiffusionControlNetPipeline.__init__() missing 7 required positional arguments: 'vae', 'text_encoder', 'tokenizer', 'unet', 'scheduler', 'safety_checker', and 'feature_extractor'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\")\n",
    "pipe = StableDiffusionControlNetPipeline(\n",
    "    controlnet=controlnet\n",
    ")\n",
    "\n",
    "# Загрузка LoRA в UNet\n",
    "pipe.unet.load_attn_procs(\"output/adapter_config.json\")\n",
    "canny_img = cv2.Canny(cv2.imread(\"data/images/plan1.png\"), 100, 200)\n",
    "canny_img = Image.fromarray(canny_img).convert(\"RGB\")\n",
    "# Использование\n",
    "image = pipe(\n",
    "    prompt=\"2 адм, 6 РВС 10к м\",\n",
    "    image=canny_img  # Ваше canny-изображение\n",
    ").images[0]\n",
    "image.save(\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f49218b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a08c9b8ea44cac86c1556556812b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_lora_weights.bin found in directory output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m pipe\u001b[38;5;241m.\u001b[39menable_model_cpu_offload()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 4. Загрузка LoRA (должна быть папка с adapter_model.bin и adapter_config.json)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_attn_procs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Указываем папку, а не файл!\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 5. Подготовка canny-изображения\u001b[39;00m\n\u001b[0;32m     30\u001b[0m canny_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCanny(cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/images/plan1.png\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\diffusers\\loaders\\unet.py:189\u001b[0m, in \u001b[0;36mUNet2DConditionLoadersMixin.load_attn_procs\u001b[1;34m(self, pretrained_model_name_or_path_or_dict, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m         model_file \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path_or_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mLORA_WEIGHT_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m load_state_dict(model_file)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nadyl\\Documents\\GitHub\\generation-of-building-diagrams\\.venv\\lib\\site-packages\\diffusers\\utils\\hub_utils.py:309\u001b[0m, in \u001b[0;36m_get_model_file\u001b[1;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model_file\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    310\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         )\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;66;03m# 1. First check if deprecated way of loading from branches is used\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    315\u001b[0m         revision \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_REVISION_ARGS\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (weights_name \u001b[38;5;241m==\u001b[39m WEIGHTS_NAME \u001b[38;5;129;01mor\u001b[39;00m weights_name \u001b[38;5;241m==\u001b[39m SAFETENSORS_WEIGHTS_NAME)\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.22.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    318\u001b[0m     ):\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_lora_weights.bin found in directory output."
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# 1. Инициализация ControlNet\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"lllyasviel/sd-controlnet-canny\", \n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 2. Правильная инициализация пайплайна\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,  # Отключаем для упрощения\n",
    "    requires_safety_checker=False\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 3. Оптимизация производительности\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# 4. Загрузка LoRA (должна быть папка с adapter_model.bin и adapter_config.json)\n",
    "pipe.unet.load_attn_procs(\"output\")  # Указываем папку, а не файл!\n",
    "\n",
    "# 5. Подготовка canny-изображения\n",
    "canny_img = cv2.Canny(cv2.imread(\"data/images/plan1.png\"), 100, 200)\n",
    "canny_img = Image.fromarray(canny_img).convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "# 6. Генерация\n",
    "image = pipe(\n",
    "    prompt=\"2 адм, 6 РВС 10к м\",\n",
    "    image=canny_img,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5\n",
    ").images[0]\n",
    "\n",
    "image.save(\"result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dc0682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eb51bd86e34f1fa9cb19b42c49eea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "LoRAAttnProcessor.__init__() got an unexpected keyword argument 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m\n\u001b[0;32m     82\u001b[0m             layer_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.processor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m             attn_processor\u001b[38;5;241m.\u001b[39mload_state_dict({\n\u001b[0;32m     84\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_q_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: state_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.to_q_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     85\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_k_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: state_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.to_k_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     86\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_v_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: state_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.to_v_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     87\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_out_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: state_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.to_out_lora.up.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     88\u001b[0m             }, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 90\u001b[0m \u001b[43mload_lora_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLORA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# ===== 3. Оптимизация =====\u001b[39;00m\n\u001b[0;32m     93\u001b[0m pipe\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;241m=\u001b[39m UniPCMultistepScheduler\u001b[38;5;241m.\u001b[39mfrom_config(pipe\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mconfig)\n",
      "Cell \u001b[1;32mIn[3], line 72\u001b[0m, in \u001b[0;36mload_lora_weights\u001b[1;34m(pipeline, lora_path)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m unet\u001b[38;5;241m.\u001b[39mattn_processors\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     71\u001b[0m     cross_attention_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn1.processor\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m unet\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcross_attention_dim\n\u001b[1;32m---> 72\u001b[0m     attn_procs[name] \u001b[38;5;241m=\u001b[39m \u001b[43mLoRAAttnProcessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnetwork_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork_alpha\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m unet\u001b[38;5;241m.\u001b[39mset_attn_processor(attn_procs)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Загружаем веса\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: LoRAAttnProcessor.__init__() got an unexpected keyword argument 'rank'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "from diffusers.models.attention_processor import LoRAAttnProcessor\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from safetensors.torch import load_file\n",
    "import json\n",
    "\n",
    "# ===== Конфигурация =====\n",
    "BASE_MODEL = \"runwayml/stable-diffusion-v1-5\"\n",
    "CONTROLNET_MODEL = \"lllyasviel/sd-controlnet-canny\"\n",
    "LORA_PATH = \"./output\"  # Папка с adapter_config.json и adapter_model.safetensors\n",
    "INPUT_IMAGE = \"data/images/plan1.png\"\n",
    "PROMPT = \"2 адм, 6 РВС 10к м\"\n",
    "OUTPUT_IMAGE = \"result.png\"\n",
    "\n",
    "# ===== 1. Инициализация пайплайна =====\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    CONTROLNET_MODEL,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False\n",
    ").to(\"cuda\")\n",
    "\n",
    "# ===== 2. Загрузка LoRA весов (современный способ) =====\n",
    "def load_lora_weights(pipeline, lora_path):\n",
    "    # Проверяем наличие файлов\n",
    "    if not os.path.exists(lora_path):\n",
    "        raise ValueError(f\"Папка {lora_path} не существует\")\n",
    "    \n",
    "    # Определяем путь к весам\n",
    "    weights_path = None\n",
    "    for filename in [\"adapter_model.safetensors\", \"adapter_model.bin\"]:\n",
    "        if os.path.exists(os.path.join(lora_path, filename)):\n",
    "            weights_path = os.path.join(lora_path, filename)\n",
    "            break\n",
    "    \n",
    "    if not weights_path:\n",
    "        raise ValueError(\"Не найден файл с весами (adapter_model.safetensors или adapter_model.bin)\")\n",
    "    \n",
    "    # Загружаем веса\n",
    "    if weights_path.endswith(\".safetensors\"):\n",
    "        state_dict = load_file(weights_path)\n",
    "    else:\n",
    "        state_dict = torch.load(weights_path, map_location=\"cpu\")\n",
    "    \n",
    "    # Создаем процессоры\n",
    "    unet = pipeline.unet\n",
    "    attn_procs = {}\n",
    "    \n",
    "    # Получаем параметры из конфига\n",
    "    config_path = os.path.join(lora_path, \"adapter_config.json\")\n",
    "    if os.path.exists(config_path):\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        rank = config.get(\"r\", 4)\n",
    "        network_alpha = config.get(\"lora_alpha\", None)\n",
    "    else:\n",
    "        rank = 4\n",
    "        network_alpha = None\n",
    "    \n",
    "    # Инициализируем процессоры\n",
    "    for name in unet.attn_processors.keys():\n",
    "        cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n",
    "        attn_procs[name] = LoRAAttnProcessor(\n",
    "            rank=rank,\n",
    "            network_alpha=network_alpha\n",
    "        )\n",
    "    \n",
    "    unet.set_attn_processor(attn_procs)\n",
    "    \n",
    "    # Загружаем веса\n",
    "    for name, attn_processor in unet.attn_processors.items():\n",
    "        if isinstance(attn_processor, LoRAAttnProcessor):\n",
    "            layer_name = name.replace(\".processor\", \"\")\n",
    "            attn_processor.load_state_dict({\n",
    "                f\"to_q_lora.up.weight\": state_dict[f\"{layer_name}.to_q_lora.up.weight\"],\n",
    "                f\"to_k_lora.up.weight\": state_dict[f\"{layer_name}.to_k_lora.up.weight\"],\n",
    "                f\"to_v_lora.up.weight\": state_dict[f\"{layer_name}.to_v_lora.up.weight\"],\n",
    "                f\"to_out_lora.up.weight\": state_dict[f\"{layer_name}.to_out_lora.up.weight\"],\n",
    "            }, strict=False)\n",
    "\n",
    "load_lora_weights(pipe, LORA_PATH)\n",
    "\n",
    "# ===== 3. Оптимизация =====\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# ===== 4. Подготовка входного изображения =====\n",
    "def prepare_canny_image(image_path, low_threshold=100, high_threshold=200):\n",
    "    image = cv2.imread(image_path)\n",
    "    canny = cv2.Canny(image, low_threshold, high_threshold)\n",
    "    canny = Image.fromarray(canny).convert(\"RGB\").resize((512, 512))\n",
    "    return canny\n",
    "\n",
    "canny_image = prepare_canny_image(INPUT_IMAGE)\n",
    "\n",
    "# ===== 5. Генерация изображения =====\n",
    "result = pipe(\n",
    "    prompt=PROMPT,\n",
    "    image=canny_image,\n",
    "    num_inference_steps=30,\n",
    "    guidance_scale=7.5,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42)\n",
    ").images[0]\n",
    "\n",
    "result.save(OUTPUT_IMAGE)\n",
    "print(f\"Изображение сохранено как {OUTPUT_IMAGE}\")\n",
    "\n",
    "# ===== Очистка =====\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "python test_lora.py --input_image data/canny/Salsk.png --prompt \"4 РВС 3к м, 4 РВС 1к м, 2 РВС 50 м, 5 ГВС 75 м, 6 ГВС 60 м\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
